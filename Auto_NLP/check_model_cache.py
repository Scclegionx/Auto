#!/usr/bin/env python3
"""
Script kiá»ƒm tra nhanh model cache
"""

import os
import sys

def check_model_cache_detailed():
    """Kiá»ƒm tra chi tiáº¿t model cache"""
    print("ğŸ” Kiá»ƒm tra chi tiáº¿t model cache...")
    
    # Kiá»ƒm tra thÆ° má»¥c gá»‘c
    if not os.path.exists('model_cache'):
        print("âŒ ThÆ° má»¥c model_cache khÃ´ng tá»“n táº¡i")
        print("ğŸ’¡ Cháº¡y: mkdir model_cache")
        return False
    
    print("âœ… ThÆ° má»¥c model_cache tá»“n táº¡i")
    
    # Kiá»ƒm tra PhoBERT-large
    phobert_large_path = 'model_cache/models--vinai--phobert-large'
    if not os.path.exists(phobert_large_path):
        print(f"âŒ {phobert_large_path} khÃ´ng tá»“n táº¡i")
        print("ğŸ’¡ Cáº§n táº£i PhoBERT-large model")
        return False
    
    print(f"âœ… {phobert_large_path} tá»“n táº¡i")
    
    # Kiá»ƒm tra ná»™i dung thÆ° má»¥c
    try:
        contents = os.listdir(phobert_large_path)
        print(f"ğŸ“ Ná»™i dung: {contents}")
        
        # Kiá»ƒm tra snapshots
        snapshots_path = os.path.join(phobert_large_path, 'snapshots')
        if os.path.exists(snapshots_path):
            snapshots = os.listdir(snapshots_path)
            print(f"ğŸ“¸ Snapshots: {snapshots}")
            
            if snapshots:
                snapshot_path = os.path.join(snapshots_path, snapshots[0])
                snapshot_contents = os.listdir(snapshot_path)
                print(f"ğŸ“„ Snapshot contents: {snapshot_contents}")
                
                # Kiá»ƒm tra cÃ¡c file quan trá»ng
                important_files = ['config.json', 'pytorch_model.bin', 'tokenizer.json']
                for file in important_files:
                    file_path = os.path.join(snapshot_path, file)
                    if os.path.exists(file_path):
                        size = os.path.getsize(file_path) / (1024*1024)  # MB
                        print(f"âœ… {file}: {size:.1f}MB")
                    else:
                        print(f"âŒ {file}: MISSING")
        else:
            print("âŒ Snapshots folder khÃ´ng tá»“n táº¡i")
            return False
            
    except Exception as e:
        print(f"âŒ Lá»—i Ä‘á»c thÆ° má»¥c: {e}")
        return False
    
    return True

def test_model_loading():
    """Test loading model"""
    print("\nğŸ§ª Test loading model...")
    
    try:
        from transformers import AutoTokenizer, AutoModel
        
        print("Táº£i tokenizer...")
        tokenizer = AutoTokenizer.from_pretrained("vinai/phobert-large")
        print("âœ… Tokenizer loaded")
        
        print("Táº£i model...")
        model = AutoModel.from_pretrained("vinai/phobert-large")
        print("âœ… Model loaded")
        
        # Test tokenization
        test_text = "Xin chÃ o"
        tokens = tokenizer(test_text, return_tensors="pt")
        print(f"âœ… Tokenization test: '{test_text}' -> {tokens['input_ids'].shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Lá»—i loading model: {e}")
        return False

def main():
    print("ğŸ” Kiá»ƒm tra model cache chi tiáº¿t...")
    print("=" * 50)
    
    # Kiá»ƒm tra cache
    cache_ok = check_model_cache_detailed()
    
    if cache_ok:
        print("\nğŸ§ª Test loading model...")
        loading_ok = test_model_loading()
        
        if loading_ok:
            print("\nâœ… Model cache hoÃ n toÃ n OK!")
        else:
            print("\nâŒ Model cache cÃ³ váº¥n Ä‘á» khi loading")
    else:
        print("\nâŒ Model cache khÃ´ng Ä‘áº§y Ä‘á»§")
        print("\nğŸ’¡ Giáº£i phÃ¡p:")
        print("1. Cháº¡y: python setup_new_machine.py")
        print("2. Hoáº·c táº£i thá»§ cÃ´ng:")
        print("   python -c \"from transformers import AutoTokenizer, AutoModel; AutoTokenizer.from_pretrained('vinai/phobert-large'); AutoModel.from_pretrained('vinai/phobert-large')\"")

if __name__ == "__main__":
    main()
