from __future__ import annotations

from pathlib import Path
from typing import Any, Dict, Optional, List, Tuple

from src.models.inference.model_loader import MultiTaskInference, _select_checkpoint


class TrainedModelInference:
    """Compatibility wrapper sá»­ dá»¥ng `MultiTaskInference` cho core hybrid system."""

    def __init__(self, model_path: str, _device: Optional[str] = None):
        model_dir = Path(model_path)
        if model_dir.is_file():
            checkpoint_path = model_dir
            model_dir = model_dir.parent
        else:
            if not model_dir.exists():
                raise FileNotFoundError(f"Model directory khÃ´ng tá»“n táº¡i: {model_dir}")
            checkpoint_path = _select_checkpoint(model_dir)

        tokenizer_path = str(model_dir)
        # Cho phÃ©p thiáº¿u config.json: MultiTaskInference sáº½ tá»± fallback sang
        # cáº¥u hÃ¬nh tá»‘i thiá»ƒu dá»±a trÃªn checkpoint + ModelConfig.*
        config_path = model_dir / "config.json"

        self._inference = MultiTaskInference(
            str(checkpoint_path),
            tokenizer_path,
            str(config_path),
        )
        self.model_loaded = True
        self.model_path = model_dir

    def predict(self, text: str) -> Dict[str, Any]:
        result = self._inference.predict(text)

        raw_entities: List[Dict[str, Any]] = result.get("entities", [])
        cleaned_entities: List[Tuple[str, str]] = []

        special_tokens = {"<s>", "</s>", "<pad>", "<unk>", "[PAD]", "[CLS]", "[SEP]"}
        platform_whitelist = {
            "zalo",
            "messenger",
            "facebook",
            "fb",
            "viber",
            "youtube",
            "zalo call",
            "zalo video",
        }

        for ent in raw_entities:
            label = ent.get("label")
            text_value = (ent.get("text") or "").strip()
            if not label or not text_value:
                continue
            if text_value in special_tokens:
                continue

            # Lá»c PLATFORM: chá»‰ giá»¯ náº¿u khá»›p whitelist (bá» cÃ¡c máº£nh nhÆ° "tin", "nháº¯n"...)
            if label == "PLATFORM":
                low = text_value.lower().strip()
                compact = low.replace(" ", "")
                if compact not in {p.replace(" ", "") for p in platform_whitelist}:
                    continue

            cleaned_entities.append((label, text_value))

        entity_map: Dict[str, Any] = {}
        message_pieces: List[str] = []
        query_pieces: List[str] = []

        # Má»™t sá»‘ label cÃ³ thá»ƒ xuáº¥t hiá»‡n nhiá»u láº§n (MESSAGE, QUERY, ...),
        # cÃ¡c label khÃ¡c thÃ¬ Æ°u tiÃªn:
        # - náº¿u chá»‰ cÃ³ 1 span: dÃ¹ng span Ä‘Ã³
        # - náº¿u cÃ³ nhiá»u span: giá»¯ span "tá»‘t" hÆ¡n (dÃ i hÆ¡n, khÃ´ng pháº£i trigger nhÆ° "báº­t", "má»Ÿ", ...)
        trigger_verbs = {"báº­t", "táº¯t", "má»Ÿ", "giáº£m", "tÄƒng", "tÃ¬m", "tra", "há»i"}

        for label, text_value in cleaned_entities:
            if label == "MESSAGE":
                message_pieces.append(text_value)
                continue

            if label == "QUERY":
                query_pieces.append(text_value)
                continue

            # CÃ¡c label khÃ¡c: DEVICE, TIME, DATE, PLATFORM, ...
            existing = entity_map.get(label)
            if existing is None:
                entity_map[label] = text_value
                continue

            # Náº¿u Ä‘Ã£ cÃ³ value cho label nÃ y, chá»n value "tá»‘t" hÆ¡n:
            # - Æ¯u tiÃªn span dÃ i hÆ¡n rÃµ rÃ ng hÆ¡n (vÃ­ dá»¥ "Ä‘iá»u hÃ²a 26 Ä‘á»™" thay cho "báº­t")
            # - Náº¿u existing lÃ  trigger verb (báº­t/táº¯t/má»Ÿ/...) vÃ  text_value dÃ i hÆ¡n => thay tháº¿
            existing_len = len(existing)
            new_len = len(text_value)

            if existing in trigger_verbs and new_len > existing_len:
                entity_map[label] = text_value
            elif new_len > existing_len and label in {"DEVICE"}:
                entity_map[label] = text_value
            # CÃ¡c trÆ°á»ng há»£p cÃ²n láº¡i: giá»¯ nguyÃªn existing Ä‘á»ƒ trÃ¡nh thay Ä‘á»•i quÃ¡ máº¡nh

        if message_pieces:
            merged = " ".join(message_pieces)
            merged = " ".join(merged.split())
            entity_map["MESSAGE"] = merged

        if query_pieces:
            # Náº¿u cÃ³ nhiá»u máº£nh QUERY, bá» bá»›t cÃ¡c trigger verb Ä‘á»©ng riÃªng láº» nhÆ° "má»Ÿ", "tÃ¬m", "tra"
            # vÃ  Æ°u tiÃªn pháº§n ná»™i dung chÃ­nh.
            filtered: List[str] = []
            for q in query_pieces:
                if q in trigger_verbs and len(query_pieces) > 1:
                    continue
                filtered.append(q)
            if not filtered:
                filtered = query_pieces
            merged_query = " ".join(filtered)
            merged_query = " ".join(merged_query.split())
            entity_map["QUERY"] = merged_query

        return {
            "intent": result.get("intent", "unknown"),
            "confidence": result.get("intent_confidence", 0.0),
            "entities": entity_map,
            "command": result.get("command", result.get("intent", "unknown")),
            "model_type": "multi-task",
        }

    def get_model_info(self) -> Dict[str, Any]:
        return {
            "model_loaded": self.model_loaded,
            "model_path": str(self.model_path),
        }

def load_trained_model(model_name: str = "phobert_multitask", device: Optional[str] = None) -> TrainedModelInference:
    """
    Load trained model
    
    Args:
        model_name: Name of the model directory
        device: Device to load model on (e.g., 'cuda', 'cpu')
        
    Returns:
        TrainedModelInference instance
    """
    model_path = Path("models") / model_name
    return TrainedModelInference(str(model_path), device)

# Test function
if __name__ == "__main__":
    print("ğŸš€ Testing TrainedModelInference...")
    
    try:
        # Load model
        model = load_trained_model("phobert_large_intent_model")
        
        # Test cases
        test_cases = [
            "gá»i Ä‘iá»‡n cho máº¹",
            "báº­t Ä‘Ã¨n phÃ²ng khÃ¡ch",
            "tÃ¬m kiáº¿m nháº¡c trÃªn youtube",
            "Ä‘áº·t bÃ¡o thá»©c 7 giá» sÃ¡ng",
            "gá»­i tin nháº¯n cho báº¡n"
        ]
        
        print(f"\nğŸ§ª Testing with {len(test_cases)} test cases...")
        
        for i, test_case in enumerate(test_cases):
            print(f"\n{i+1}. Testing: '{test_case}'")
            result = model.predict(test_case)
            print(f"   Intent: {result['intent']}")
            print(f"   Confidence: {result['confidence']:.3f}")
            print(f"   Command: {result['command']}")
            print(f"   Entities: {result['entities']}")
            print(f"   Model type: {result['model_type']}")
        
        # Print model info
        print(f"\nğŸ“Š Model Info:")
        info = model.get_model_info()
        for key, value in info.items():
            print(f"   {key}: {value}")
        
        print(f"\nâœ… TrainedModelInference test completed!")
        
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        import traceback
        traceback.print_exc()
