
import sys
import os
import gc
import torch
from pathlib import Path

# Set environment variables for stability
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'

current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))
sys.path.insert(0, str(current_dir / "src"))
sys.path.insert(0, str(current_dir / "src" / "training" / "configs"))
sys.path.insert(0, str(current_dir / "src" / "models" / "base"))
sys.path.insert(0, str(current_dir / "src" / "training" / "utils"))

def clean_old_data():
    """Clean old training data before starting new training"""
    print("üßπ Cleaning old training data...")
    
    # Clean model checkpoints
    model_dirs = ["models", "src/models/trained"]
    for model_dir in model_dirs:
        if Path(model_dir).exists():
            import shutil
            shutil.rmtree(model_dir)
            print(f"‚úÖ Removed: {model_dir}")
    
    # Clean log files
    import glob
    log_files = glob.glob("*.log")
    for log_file in log_files:
        os.remove(log_file)
        print(f"‚úÖ Removed: {log_file}")
    
    # Clean cache
    cache_dirs = ["model_cache", "__pycache__"]
    for cache_dir in cache_dirs:
        if Path(cache_dir).exists():
            import shutil
            shutil.rmtree(cache_dir)
            print(f"‚úÖ Removed: {cache_dir}")
    
    # Create fresh directories
    os.makedirs("models", exist_ok=True)
    os.makedirs("logs", exist_ok=True)
    print("‚úÖ Created fresh directories")

def main():
    print("üöÄ CH·∫†Y TRAINING T·ª™ C·∫§U TR√öC M·ªöI")
    print("=" * 50)
    
    # Clean old data first
    clean_old_data()
    
    # C·∫•u h√¨nh t·ªëi ∆∞u cho GPU 6GB
    os.environ['MAX_LENGTH'] = '64'
    os.environ['BATCH_SIZE'] = '2'
    print("üéÆ Optimized configuration for GPU 6GB:")
    print("   - Max Length: 64")
    print("   - Batch Size: 2")
    print("   - Gradient Accumulation: 4 (effective batch 8)")
    
    # Clear GPU cache before starting (only if CUDA is actually available)
    if torch.cuda.is_available() and 'CUDA_VISIBLE_DEVICES' not in os.environ:
        try:
            torch.cuda.empty_cache()
            gc.collect()
            print(f"üßπ GPU cache cleared. Available memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
        except RuntimeError as e:
            print(f"‚ö†Ô∏è Could not clear GPU cache: {e}")
            print("üñ•Ô∏è Continuing with CPU training...")
    else:
        print("üñ•Ô∏è Using CPU training (CUDA disabled)")
    
    try:
        from src.training.scripts.train_gpu import main as train_main
        print("üîß Starting training with improved error handling...")
        train_main()
    except ImportError as e:
        print(f"‚ùå L·ªói import: {e}")
        print("üîß Th·ª≠ ch·∫°y tr·ª±c ti·∫øp...")
        
        import subprocess
        result = subprocess.run([
            sys.executable, 
            "src/training/scripts/train_gpu.py"
        ], cwd=current_dir)
        
        if result.returncode == 0:
            print("‚úÖ Training ho√†n th√†nh!")
        else:
            print("‚ùå Training th·∫•t b·∫°i!")
    except Exception as e:
        print(f"‚ùå L·ªói training: {e}")
        print("üîß Th·ª≠ ch·∫°y v·ªõi c·∫•u h√¨nh an to√†n h∆°n...")
        
        # Try with reduced batch size
        try:
            import subprocess
            env = os.environ.copy()
            env['BATCH_SIZE'] = '2'
            env['MAX_LENGTH'] = '64'
            
            result = subprocess.run([
                sys.executable, 
                "src/training/scripts/train_gpu.py"
            ], cwd=current_dir, env=env)
            
            if result.returncode == 0:
                print("‚úÖ Training ho√†n th√†nh v·ªõi c·∫•u h√¨nh an to√†n!")
            else:
                print("‚ùå Training v·∫´n th·∫•t b·∫°i!")
                
        except Exception as e2:
            print(f"‚ùå L·ªói cu·ªëi c√πng: {e2}")

if __name__ == "__main__":
    main()
