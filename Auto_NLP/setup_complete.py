#!/usr/bin/env python3

import os
import sys
import subprocess
import shutil
import warnings
from pathlib import Path

def print_step(step, description):
    print(f"\n{'='*60}")
    print(f"B∆Ø·ªöC {step}: {description}")
    print('='*60)

def run_command(cmd, description="", ignore_errors=False):
    if description:
        print(f"üîÑ {description}")
    
    try:
        result = subprocess.run(cmd, shell=True, check=True, capture_output=True, text=True)
        print(f"‚úÖ Th√†nh c√¥ng: {description}")
        return True
    except subprocess.CalledProcessError as e:
        if ignore_errors:
            print(f"‚ö†Ô∏è B·ªè qua: {description}")
            return True
        else:
            print(f"‚ùå L·ªói: {description}")
            print(f"   Error: {e.stderr}")
            return False

def check_python_version():
    print_step(1, "KI·ªÇM TRA PYTHON VERSION")
    
    version = sys.version_info
    print(f"Python version: {version.major}.{version.minor}.{version.micro}")
    
    if version.major < 3 or (version.major == 3 and version.minor < 8):
        print("‚ùå C·∫ßn Python 3.8+ ƒë·ªÉ ch·∫°y d·ª± √°n")
        return False
    
    print("‚úÖ Python version OK")
    return True

def create_virtual_environment():
    print_step(2, "T·∫†O VIRTUAL ENVIRONMENT")
    
    venv_path = Path("venv_new")
    
    if venv_path.exists():
        print("üóëÔ∏è X√≥a venv c≈©...")
        shutil.rmtree(venv_path)
    
    print("üì¶ T·∫°o venv m·ªõi...")
    if not run_command("python -m venv venv_new", "T·∫°o virtual environment"):
        return False
    
    return True

def install_packages():
    print_step(3, "C√ÄI ƒê·∫∂T PACKAGES")
    
    warnings.filterwarnings("ignore")
    
    # Uninstall packages c≈© tr∆∞·ªõc
    print("üóëÔ∏è Uninstall packages c≈©...")
    old_packages = [
        "torch", "torchvision", "torchaudio", "transformers", "datasets", "accelerate",
        "scikit-learn", "seqeval", "numpy", "pandas", "tqdm", "matplotlib", "seaborn",
        "wandb", "tensorboard", "underthesea", "pyvi", "fastapi", "uvicorn", "faiss-cpu",
        "rapidfuzz", "peft", "optuna", "bitsandbytes", "ray", "pydantic", "regex"
    ]
    
    for package in old_packages:
        cmd = f"venv_new\\Scripts\\pip uninstall {package} -y"
        run_command(cmd, f"Uninstall {package}", ignore_errors=True)
    
    # C√†i ƒë·∫∑t packages m·ªõi v·ªõi phi√™n b·∫£n c·ª• th·ªÉ
    packages = [
        # Core ML packages
        "torch>=2.5.0 --index-url https://download.pytorch.org/whl/cu121",
        "torchvision>=0.20.0 --index-url https://download.pytorch.org/whl/cu121", 
        "torchaudio>=2.5.0 --index-url https://download.pytorch.org/whl/cu121",
        "transformers>=4.30.0",
        "datasets>=2.12.0",
        "accelerate>=0.20.0",
        
        # ML utilities
        "scikit-learn>=1.3.0",
        "seqeval>=1.2.2",
        "numpy>=1.24.0",
        "pandas>=2.0.0",
        "tqdm>=4.65.0",
        
        # Visualization
        "matplotlib>=3.7.0",
        "seaborn>=0.12.0",
        
        # Logging and monitoring
        "wandb>=0.15.0",
        "tensorboard>=2.13.0",
        
        # Vietnamese NLP
        "underthesea>=6.6.0",
        "pyvi>=0.1.1",
        
        # API and web
        "fastapi>=0.100.0",
        "uvicorn>=0.20.0",
        "pydantic>=2.0.0",
        
        # Search and similarity
        "faiss-cpu>=1.7.0",
        "rapidfuzz>=3.0.0",
        
        # Advanced training
        "peft>=0.4.0",
        "optuna>=3.0.0",
        "bitsandbytes>=0.41.0",
        
        # Text processing
        "regex>=2021.0.0",
        
        # Additional utilities
        "pyyaml>=6.0",
        "requests>=2.28.0",
        "click>=8.0.0",
        "colorama>=0.4.0"
    ]
    
    for package in packages:
        cmd = f"venv_new\\Scripts\\pip install {package}"
        if not run_command(cmd, f"C√†i ƒë·∫∑t {package.split()[0]}"):
            return False
    
    return True

def clear_model_cache():
    print_step(4, "X√ìA MODEL CACHE C≈®")
    
    cache_paths = [
        Path.home() / ".cache" / "huggingface",
        Path("model_cache"),
        Path("models")
    ]
    
    for cache_path in cache_paths:
        if cache_path.exists():
            print(f"üóëÔ∏è X√≥a cache: {cache_path}")
            shutil.rmtree(cache_path, ignore_errors=True)
    
    return True

def download_models():
    print_step(5, "T·∫¢I MODEL PHOBERT-LARGE")
    
    test_script = """
import warnings
warnings.filterwarnings("ignore")

try:
    from transformers import AutoTokenizer, AutoModel
    import torch
    
    print("üì• ƒêang t·∫£i PhoBERT-large...")
    
    tokenizer = AutoTokenizer.from_pretrained(
        "vinai/phobert-large",
        cache_dir="model_cache",
        force_download=True
    )
    
    model = AutoModel.from_pretrained(
        "vinai/phobert-large", 
        cache_dir="model_cache",
        force_download=True
    )
    
    test_text = "Xin ch√†o"
    inputs = tokenizer(test_text, return_tensors="pt")
    outputs = model(**inputs)
    
    print("‚úÖ Model t·∫£i th√†nh c√¥ng!")
    print(f"   - Tokenizer: {type(tokenizer).__name__}")
    print(f"   - Model: {type(model).__name__}")
    print(f"   - Output shape: {outputs.last_hidden_state.shape}")
    
except Exception as e:
    print(f"‚ùå L·ªói t·∫£i model: {e}")
    exit(1)
"""
    
    with open("test_model_download.py", "w", encoding="utf-8") as f:
        f.write(test_script)
    
    success = run_command("venv_new\\Scripts\\python test_model_download.py", "T·∫£i v√† test model")
    
    if os.path.exists("test_model_download.py"):
        os.remove("test_model_download.py")
    
    return success

def test_training_script():
    print_step(6, "KI·ªÇM TRA TRAINING SCRIPT")
    
    train_script = Path("src/training/scripts/train_gpu.py")
    if not train_script.exists():
        print("‚ùå Kh√¥ng t√¨m th·∫•y train_gpu.py")
        return False
    
    print("‚úÖ Training script t·ªìn t·∫°i")
    
    test_imports = """
try:
    import torch
    import transformers
    from transformers import AutoTokenizer, AutoModel
    print("‚úÖ All imports OK")
    print(f"PyTorch: {torch.__version__}")
    print(f"CUDA: {torch.cuda.is_available()}")
except Exception as e:
    print(f"‚ùå Import error: {e}")
    exit(1)
"""
    
    with open("test_imports.py", "w", encoding="utf-8") as f:
        f.write(test_imports)
    
    success = run_command("venv_new\\Scripts\\python test_imports.py", "Test imports")
    
    if os.path.exists("test_imports.py"):
        os.remove("test_imports.py")
    
    return success

def main():
    print("üöÄ AUTO NLP - SETUP CHO NG∆Ø·ªúI M·ªöI")
    print("=" * 60)
    print("Script n√†y s·∫Ω setup ho√†n ch·ªânh d·ª± √°n cho ng∆∞·ªùi m·ªõi clone v·ªÅ")
    print("=" * 60)
    
    steps = [
        check_python_version,
        create_virtual_environment, 
        install_packages,
        clear_model_cache,
        download_models,
        test_training_script
    ]
    
    for i, step_func in enumerate(steps, 1):
        if not step_func():
            print(f"\n‚ùå B∆Ø·ªöC {i} TH·∫§T B·∫†I!")
            print("Vui l√≤ng ki·ªÉm tra l·ªói v√† th·ª≠ l·∫°i")
            return False
    
    print("\n" + "="*60)
    print("üéâ SETUP HO√ÄN TH√ÄNH TH√ÄNH C√îNG!")
    print("="*60)
    print("\nüìã B∆Ø·ªöC TI·∫æP THEO:")
    print("1. Activate virtual environment:")
    print("   venv_new\\Scripts\\activate")
    print("\n2. Ch·∫°y training:")
    print("   python src/training/scripts/train_gpu.py")
    print("\n3. Ho·∫∑c ch·∫°y API:")
    print("   python api/server.py")
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)