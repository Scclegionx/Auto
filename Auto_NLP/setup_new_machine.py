#!/usr/bin/env python3
"""
Script setup cho m√°y m·ªõi
"""

import subprocess
import sys
import os

def install_requirements():
    """C√†i ƒë·∫∑t requirements"""
    print("üì¶ C√†i ƒë·∫∑t requirements...")
    
    requirements = [
        'torch>=2.5.0',  # Compatible with current version
        'transformers>=4.20.0',
        'scikit-learn>=1.0.0',
        'seqeval>=1.2.0',
        'tqdm>=4.60.0',
        'numpy>=1.21.0',
        'regex>=2021.0.0',
        'fastapi>=0.70.0',
        'uvicorn>=0.15.0'
    ]
    
    for req in requirements:
        try:
            subprocess.check_call([sys.executable, '-m', 'pip', 'install', req])
            print(f"‚úÖ ƒê√£ c√†i {req}")
        except subprocess.CalledProcessError:
            print(f"‚ùå L·ªói c√†i {req}")

def check_model_cache():
    """Ki·ªÉm tra model cache"""
    print("üîç Ki·ªÉm tra model cache...")
    
    cache_paths = [
        'model_cache',
        'model_cache/models--vinai--phobert-large'
    ]
    
    missing_cache = []
    
    for cache_path in cache_paths:
        if os.path.exists(cache_path):
            print(f"‚úÖ {cache_path}: OK")
        else:
            print(f"‚ùå {cache_path}: MISSING")
            missing_cache.append(cache_path)
    
    if missing_cache:
        print(f"‚ö†Ô∏è Thi·∫øu model cache: {missing_cache}")
        print("üîÑ S·∫Ω t·ª± ƒë·ªông t·∫£i model...")
        return False
    else:
        print("‚úÖ Model cache OK")
        return True

def download_models():
    """T·∫£i models"""
    print("ü§ñ T·∫£i PhoBERT-large model...")
    
    try:
        import warnings
        # Suppress vulnerability warnings for PyTorch < 2.6
        warnings.filterwarnings("ignore", message=".*vulnerability.*")
        
        from transformers import AutoTokenizer, AutoModel
        
        # Force download l·∫°i ƒë·ªÉ ƒë·∫£m b·∫£o c√≥ ƒë·∫ßy ƒë·ªß files
        print("T·∫£i PhoBERT-large tokenizer...")
        tokenizer = AutoTokenizer.from_pretrained(
            "vinai/phobert-large",
            force_download=True,  # Force download
            cache_dir="model_cache"
        )
        
        print("T·∫£i PhoBERT-large model...")
        model = AutoModel.from_pretrained(
            "vinai/phobert-large",
            force_download=True,  # Force download
            cache_dir="model_cache"
        )
        
        print("‚úÖ ƒê√£ t·∫£i PhoBERT-large model")
        
        # Test loading ƒë·ªÉ ƒë·∫£m b·∫£o ho·∫°t ƒë·ªông
        print("üß™ Test loading model...")
        test_text = "Xin ch√†o"
        tokens = tokenizer(test_text, return_tensors="pt")
        print(f"‚úÖ Test OK: '{test_text}' -> {tokens['input_ids'].shape}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå L·ªói t·∫£i model: {e}")
        print("üí° Tip: Ki·ªÉm tra k·∫øt n·ªëi internet v√† th·ª≠ l·∫°i")
        print("üí° Tip: N·∫øu g·∫∑p vulnerability warning, c√≥ th·ªÉ b·ªè qua")
        return False

def main():
    print("üöÄ Setup cho m√°y m·ªõi...")
    
    # T·∫°o th∆∞ m·ª•c c·∫ßn thi·∫øt
    os.makedirs('model_cache', exist_ok=True)
    os.makedirs('models', exist_ok=True)
    os.makedirs('logs', exist_ok=True)
    
    # C√†i ƒë·∫∑t requirements
    install_requirements()
    
    # Ki·ªÉm tra model cache
    cache_ok = check_model_cache()
    
    # T·∫£i models n·∫øu thi·∫øu
    if not cache_ok:
        success = download_models()
        if not success:
            print("‚ùå Setup th·∫•t b·∫°i - kh√¥ng th·ªÉ t·∫£i model")
            return False
    
    print("‚úÖ Setup ho√†n th√†nh!")
    print("\nüìã B∆∞·ªõc ti·∫øp theo:")
    print("1. Ch·∫°y: python src/training/scripts/train_gpu.py")
    print("2. Ho·∫∑c ch·∫°y: python api/server.py (cho API)")
    return True

if __name__ == "__main__":
    main()
