"""
Entity Extractor Module cho h·ªá th·ªëng g·ªçi ƒëi·ªán/nh·∫Øn tin
T·∫≠p trung v√†o RECEIVER, TIME, MESSAGE, PLATFORM extraction
"""

import re
from typing import Dict, List, Optional, Tuple

class EntityExtractor:
    """Entity extractor chuy√™n bi·ªát cho h·ªá th·ªëng g·ªçi ƒëi·ªán/nh·∫Øn tin"""
    
    def __init__(self):
        self.receiver_patterns = self._build_receiver_patterns()
        self.time_patterns = self._build_time_patterns()
        self.message_patterns = self._build_message_patterns()
        self.platform_patterns = self._build_platform_patterns()
        
    def _build_receiver_patterns(self) -> List[Tuple[str, str]]:
        """X√¢y d·ª±ng patterns cho RECEIVER extraction - T·ªëi ∆∞u cho ng∆∞·ªùi gi√†"""
        return [
            # Pattern 1: G·ªçi tr·ª±c ti·∫øp (∆∞u ti√™n cao)
            (r"g·ªçi\s+(?:cho|t·ªõi|ƒë·∫øn)?\s*([\w\s]+?)(?:\s+(?:l√∫c|v√†o|nh√©|nha|·∫°|nh√°|ngay|b√¢y gi·ªù))?(?:$|[\.,])", "g·ªçi"),
            (r"alo\s+(?:cho|t·ªõi|ƒë·∫øn)?\s*([\w\s]+?)(?:\s+(?:l√∫c|v√†o|nh√©|nha|·∫°|nh√°|ngay|b√¢y gi·ªù))?(?:$|[\.,])", "g·ªçi"),
            (r"g·ªçi\s+ƒëi·ªán\s+(?:cho|t·ªõi|ƒë·∫øn)?\s*([\w\s]+?)(?:\s+(?:l√∫c|v√†o|nh√©|nha|·∫°|nh√°|ngay|b√¢y gi·ªù))?(?:$|[\.,])", "g·ªçi"),
            (r"g·ªçi\s+tho·∫°i\s+(?:cho|t·ªõi|ƒë·∫øn)?\s*([\w\s]+?)(?:\s+(?:l√∫c|v√†o|nh√©|nha|·∫°|nh√°|ngay|b√¢y gi·ªù))?(?:$|[\.,])", "g·ªçi"),
            
            # Pattern 2: Nh·∫Øn tin (∆∞u ti√™n cao)
            (r"nh·∫Øn\s+(?:tin|tin nh·∫Øn)?\s+(?:cho|t·ªõi|ƒë·∫øn)?\s*([\w\s]+?)(?:\s+(?:r·∫±ng|l√†|n√≥i|nh√©|nha|·∫°|nh√°))?(?:$|[\.,])", "nh·∫Øn"),
            (r"g·ª≠i\s+(?:tin|tin nh·∫Øn)?\s+(?:cho|t·ªõi|ƒë·∫øn)?\s*([\w\s]+?)(?:\s+(?:r·∫±ng|l√†|n√≥i|nh√©|nha|·∫°|nh√°))?(?:$|[\.,])", "nh·∫Øn"),
            (r"so·∫°n\s+tin\s+(?:cho|t·ªõi|ƒë·∫øn)?\s*([\w\s]+?)(?:\s+(?:r·∫±ng|l√†|n√≥i|nh√©|nha|·∫°|nh√°))?(?:$|[\.,])", "nh·∫Øn"),
            
            # Pattern 3: V·ªõi platform (c·∫£i thi·ªán ƒë·ªÉ extract ch√≠nh x√°c)
            (r"nh·∫Øn\s+tin\s+qua\s+[\w\s]+\s+(?:cho|t·ªõi|ƒë·∫øn)?\s*([\w\s]+?)(?:\s+(?:r·∫±ng|l√†|n√≥i|nh√©|nha|·∫°|nh√°))", "nh·∫Øn"),
            (r"g·ª≠i\s+tin\s+qua\s+[\w\s]+\s+(?:cho|t·ªõi|ƒë·∫øn)?\s*([\w\s]+?)(?:\s+(?:r·∫±ng|l√†|n√≥i|nh√©|nha|·∫°|nh√°))", "nh·∫Øn"),
            
            # Pattern 4: Video call
            (r"g·ªçi\s+video\s+(?:cho|t·ªõi|ƒë·∫øn)?\s*([\w\s]+?)(?:\s+(?:l√∫c|v√†o|nh√©|nha|·∫°|nh√°|ngay|b√¢y gi·ªù))?(?:$|[\.,])", "video"),
            (r"facetime\s+(?:v·ªõi|cho|t·ªõi|ƒë·∫øn)?\s*([\w\s]+?)(?:\s+(?:l√∫c|v√†o|nh√©|nha|·∫°|nh√°|ngay|b√¢y gi·ªù))?(?:$|[\.,])", "video"),
            (r"video\s+call\s+(?:cho|t·ªõi|ƒë·∫øn)?\s*([\w\s]+?)(?:\s+(?:l√∫c|v√†o|nh√©|nha|·∫°|nh√°|ngay|b√¢y gi·ªù))?(?:$|[\.,])", "video"),
            
            # Pattern 5: Kh·∫©n c·∫•p
            (r"g·ªçi\s+ngay\s+(?:cho|t·ªõi|ƒë·∫øn)?\s*([\w\s]+?)(?:\s+(?:l√∫c|v√†o|nh√©|nha|·∫°|nh√°))?(?:$|[\.,])", "g·ªçi"),
            (r"g·ªçi\s+kh·∫©n\s+c·∫•p\s+(?:cho|t·ªõi|ƒë·∫øn)?\s*([\w\s]+?)(?:\s+(?:l√∫c|v√†o|nh√©|nha|·∫°|nh√°))?(?:$|[\.,])", "g·ªçi"),
            
            # Pattern 6: Nhi·ªÅu ng∆∞·ªùi (t·ªëi ∆∞u cho gia ƒë√¨nh)
            (r"g·ªçi\s+cho\s+(?:c·∫£\s+nh√†|t·∫•t\s+c·∫£|m·ªçi\s+ng∆∞·ªùi|con\s+ch√°u|gia\s+ƒë√¨nh)", "g·ªçi"),
            (r"nh·∫Øn\s+tin\s+cho\s+(?:c·∫£\s+nh√†|t·∫•t\s+c·∫£|m·ªçi\s+ng∆∞·ªùi|con\s+ch√°u|gia\s+ƒë√¨nh)", "nh·∫Øn"),
            
            # Pattern 7: Quan h·ªá ph·ª©c t·∫°p (t·ªëi ∆∞u cho ng∆∞·ªùi gi√†)
            (r"g·ªçi\s+cho\s+([\w\s]+?)\s+(?:c·ªßa|·ªü|t·∫°i)\s+[\w\s]+", "g·ªçi"),
            (r"nh·∫Øn\s+tin\s+cho\s+([\w\s]+?)\s+(?:c·ªßa|·ªü|t·∫°i)\s+[\w\s]+", "nh·∫Øn"),
            
            # Pattern 8: Quan h·ªá gia ƒë√¨nh (th√™m m·ªõi)
            (r"g·ªçi\s+cho\s+(?:b·ªë|m·∫π|√¥ng|b√†|anh|ch·ªã|em|con|ch√°u|ch√∫|b√°c|c√¥|d√¨|d∆∞·ª£ng|m·ª£)", "g·ªçi"),
            (r"nh·∫Øn\s+tin\s+cho\s+(?:b·ªë|m·∫π|√¥ng|b√†|anh|ch·ªã|em|con|ch√°u|ch√∫|b√°c|c√¥|d√¨|d∆∞·ª£ng|m·ª£)", "nh·∫Øn"),
            
            # Pattern 9: T√™n ri√™ng (th√™m m·ªõi)
            (r"g·ªçi\s+cho\s+([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)", "g·ªçi"),
            (r"nh·∫Øn\s+tin\s+cho\s+([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)", "nh·∫Øn"),
            
            # Pattern 10: Fallback patterns
            (r"cho\s+([\w\s]+?)(?:\s+(?:nh√©|nha|·∫°|nh√°|ngay b√¢y gi·ªù|ngay|b√¢y gi·ªù))?(?:$|[\.,])", "g·ªçi"),
            (r"(?:cu·ªôc g·ªçi|g·ªçi ƒëi·ªán|g·ªçi tho·∫°i)\s+(?:cho|t·ªõi|ƒë·∫øn)\s+([\w\s]+?)(?:\s+(?:nh√©|nha|·∫°|nh√°|ngay b√¢y gi·ªù|ngay|b√¢y gi·ªù))?(?:$|[\.,])", "g·ªçi"),
        ]
    
    def _build_time_patterns(self) -> List[str]:
        """X√¢y d·ª±ng patterns cho TIME extraction - T·ªëi ∆∞u cho ng∆∞·ªùi gi√†"""
        return [
            # Th·ªùi gian c·ª• th·ªÉ (∆∞u ti√™n cao)
            r"(\d{1,2})\s*gi·ªù\s*(\d{1,2})?\s*(?:ph√∫t)?\s*(?:s√°ng|tr∆∞a|chi·ªÅu|t·ªëi|ƒë√™m)?",
            r"(\d{1,2})\s*r∆∞·ª°i\s*(?:s√°ng|tr∆∞a|chi·ªÅu|t·ªëi|ƒë√™m)?",
            r"(\d{1,2})\s*gi·ªù\s*r∆∞·ª°i\s*(?:s√°ng|tr∆∞a|chi·ªÅu|t·ªëi|ƒë√™m)?",
            r"(\d{1,2})\s*gi·ªù\s*(?:k√©m|thi·∫øu)\s*(\d{1,2})",
            
            # Th·ªùi gian t∆∞∆°ng ƒë·ªëi (t·ªëi ∆∞u cho ng∆∞·ªùi gi√†)
            r"(s√°ng|tr∆∞a|chi·ªÅu|t·ªëi|ƒë√™m)\s*(?:nay|mai|kia)?",
            r"(h√¥m\s+nay|ng√†y\s+mai|tu·∫ßn\s+sau|th√°ng\s+sau)",
            r"(sau\s+(?:khi\s+)?ƒÉn|sau\s+b·ªØa\s+(?:s√°ng|tr∆∞a|t·ªëi))",
            r"(tr∆∞·ªõc\s+(?:khi\s+)?ƒÉn|tr∆∞·ªõc\s+b·ªØa\s+(?:s√°ng|tr∆∞a|t·ªëi))",
            
            # Th·ªùi gian kh·∫©n c·∫•p
            r"(ngay|ngay\s+b√¢y\s+gi·ªù|b√¢y\s+gi·ªù|l·∫≠p\s+t·ª©c)",
            r"(khi\s+n√†o|khi\s+ƒë√≥|l√∫c\s+ƒë√≥)",
            
            # Th·ªùi gian ƒë·ªãnh k·ª≥ (th√™m m·ªõi)
            r"(h√†ng\s+ng√†y|h√†ng\s+tu·∫ßn|h√†ng\s+th√°ng)",
            r"(th·ª©\s+\d+\s+h√†ng\s+tu·∫ßn)",
            r"(ng√†y\s+\d+\s+h√†ng\s+th√°ng)",
            
            # Th·ªùi gian theo b·ªØa ƒÉn (t·ªëi ∆∞u cho ng∆∞·ªùi gi√†)
            r"(sau\s+b·ªØa\s+s√°ng|sau\s+b·ªØa\s+tr∆∞a|sau\s+b·ªØa\s+t·ªëi)",
            r"(tr∆∞·ªõc\s+b·ªØa\s+s√°ng|tr∆∞·ªõc\s+b·ªØa\s+tr∆∞a|tr∆∞·ªõc\s+b·ªØa\s+t·ªëi)",
            
            # Th·ªùi gian theo ho·∫°t ƒë·ªông (th√™m m·ªõi)
            r"(sau\s+khi\s+ng·ªß|tr∆∞·ªõc\s+khi\s+ng·ªß)",
            r"(sau\s+khi\s+ƒëi\s+ch·ª£|tr∆∞·ªõc\s+khi\s+ƒëi\s+ch·ª£)",
            r"(sau\s+khi\s+ƒëi\s+b·ªánh\s+vi·ªán|tr∆∞·ªõc\s+khi\s+ƒëi\s+b·ªánh\s+vi·ªán)",
        ]
    
    def _build_message_patterns(self) -> List[str]:
        """X√¢y d·ª±ng patterns cho MESSAGE extraction - T·ªëi ∆∞u cho ng∆∞·ªùi gi√†"""
        return [
            # Pattern 1: R·∫±ng l√† (∆∞u ti√™n cao)
            r"r·∫±ng\s+l√†\s+(.+?)(?:\s+(?:nh√©|nha|·∫°|nh√°))?(?:$|[\.,])",
            r"r·∫±ng\s+(.+?)(?:\s+(?:nh√©|nha|·∫°|nh√°))?(?:$|[\.,])",
            
            # Pattern 2: L√†
            r"l√†\s+(.+?)(?:\s+(?:nh√©|nha|·∫°|nh√°))?(?:$|[\.,])",
            
            # Pattern 3: N√≥i
            r"n√≥i\s+(.+?)(?:\s+(?:nh√©|nha|·∫°|nh√°))?(?:$|[\.,])",
            r"n√≥i\s+r√µ\s+l√†\s+(.+?)(?:\s+(?:nh√©|nha|·∫°|nh√°))?(?:$|[\.,])",
            
            # Pattern 4: Nh·∫Øn/G·ª≠i
            r"nh·∫Øn\s+(.+?)(?:\s+(?:nh√©|nha|·∫°|nh√°))?(?:$|[\.,])",
            r"g·ª≠i\s+(.+?)(?:\s+(?:nh√©|nha|·∫°|nh√°))?(?:$|[\.,])",
            
            # Pattern 5: V·ªõi n·ªôi dung trong ngo·∫∑c
            r"[\"'](.+?)[\"']",
            
            # Pattern 6: Sau t·ª´ kh√≥a
            r"(?:n·ªôi\s+dung|tin\s+nh·∫Øn)\s+(?:l√†|r·∫±ng)?\s+(.+?)(?:\s+(?:nh√©|nha|·∫°|nh√°))?(?:$|[\.,])",
            
            # Pattern 7: Tin nh·∫Øn d√†i (th√™m m·ªõi)
            r"nh·∫Øn\s+tin\s+cho\s+[\w\s]+\s+r·∫±ng\s+(.+?)(?:\s+(?:nh√©|nha|·∫°|nh√°))?(?:$|[\.,])",
            r"g·ª≠i\s+tin\s+cho\s+[\w\s]+\s+r·∫±ng\s+(.+?)(?:\s+(?:nh√©|nha|·∫°|nh√°))?(?:$|[\.,])",
            
            # Pattern 8: Tin nh·∫Øn v·ªõi th·ªùi gian (th√™m m·ªõi)
            r"nh·∫Øn\s+tin\s+cho\s+[\w\s]+\s+r·∫±ng\s+(.+?)\s+l√∫c\s+[\w\s]+",
            r"g·ª≠i\s+tin\s+cho\s+[\w\s]+\s+r·∫±ng\s+(.+?)\s+l√∫c\s+[\w\s]+",
        ]
    
    def _build_platform_patterns(self) -> List[str]:
        """X√¢y d·ª±ng patterns cho PLATFORM extraction - T·ªëi ∆∞u cho ng∆∞·ªùi gi√†"""
        return [
            # Pattern 1: Qua/B·∫±ng/Tr√™n (∆∞u ti√™n cao)
            r"qua\s+(zalo|messenger|youtube|facebook|sms|tin\s+nh·∫Øn)",
            r"b·∫±ng\s+(zalo|messenger|youtube|facebook|sms|tin\s+nh·∫Øn)",
            r"tr√™n\s+(zalo|messenger|youtube|facebook|sms|tin\s+nh·∫Øn)",
            r"s·ª≠\s+d·ª•ng\s+(zalo|messenger|youtube|facebook|sms|tin\s+nh·∫Øn)",
            r"d√πng\s+(zalo|messenger|youtube|facebook|sms|tin\s+nh·∫Øn)",
            
            # Pattern 2: Tr·ª±c ti·∫øp (th√™m m·ªõi)
            r"(zalo|messenger|youtube|facebook|sms|tin\s+nh·∫Øn)",
            
            # Pattern 3: T√™n g·ªçi kh√°c (th√™m m·ªõi)
            r"(zalo|messenger|youtube|facebook|sms|tin\s+nh·∫Øn|facebook|youtube)",
            
            # Pattern 4: T√™n g·ªçi th√¢n thi·ªán (th√™m m·ªõi)
            r"(zalo|messenger|youtube|facebook|sms|tin\s+nh·∫Øn|facebook|youtube|google)",
        ]
    
    def extract_receiver(self, text: str) -> Optional[Dict[str, str]]:
        """Extract RECEIVER entity v·ªõi ƒë·ªô ch√≠nh x√°c cao"""
        text_lower = text.lower()
        
        for pattern, action_type in self.receiver_patterns:
            match = re.search(pattern, text_lower, re.IGNORECASE)
            if match and match.group(1):
                receiver = match.group(1).strip()
                
                # L√†m s·∫°ch receiver
                receiver = self._clean_receiver(receiver)
                
                if receiver and len(receiver) > 1:
                    return {
                        "RECEIVER": receiver,
                        "ACTION_TYPE": action_type
                    }
        
        return None
    
    def extract_time(self, text: str) -> Optional[str]:
        """Extract TIME entity"""
        text_lower = text.lower()
        
        for pattern in self.time_patterns:
            match = re.search(pattern, text_lower, re.IGNORECASE)
            if match:
                if match.groups():
                    time_value = " ".join([g for g in match.groups() if g])
                    if time_value:
                        return time_value.strip()
                else:
                    return match.group(0).strip()
        
        return None
    
    def extract_message(self, text: str, receiver: str = None) -> Optional[str]:
        """Extract MESSAGE entity"""
        text_lower = text.lower()
        
        for pattern in self.message_patterns:
            match = re.search(pattern, text_lower, re.IGNORECASE)
            if match and match.group(1):
                message = match.group(1).strip()
                
                # L√†m s·∫°ch message
                message = self._clean_message(message)
                
                if message and len(message) > 3:
                    return message
        
        return None
    
    def extract_platform(self, text: str) -> str:
        """Extract PLATFORM entity v·ªõi logic th√¥ng minh"""
        text_lower = text.lower()
        
        for pattern in self.platform_patterns:
            match = re.search(pattern, text_lower, re.IGNORECASE)
            if match and match.group(1):
                platform = match.group(1).lower()
                return platform
        
        # Logic th√¥ng minh d·ª±a tr√™n context
        if any(word in text_lower for word in ["g·ªçi", "alo", "g·ªçi ƒëi·ªán", "g·ªçi tho·∫°i"]):
            return "phone"
        elif any(word in text_lower for word in ["nh·∫Øn", "g·ª≠i", "tin nh·∫Øn", "sms"]):
            return "sms"
        elif any(word in text_lower for word in ["t√¨m", "t√¨m ki·∫øm", "search", "youtube", "facebook"]):
            return "youtube" if "youtube" in text_lower else "facebook" if "facebook" in text_lower else "google"
        else:
            return "sms"
    
    def _clean_receiver(self, receiver: str) -> str:
        """L√†m s·∫°ch receiver entity - T·ªëi ∆∞u cho ng∆∞·ªùi gi√†"""
        unwanted_words = [
            "r·∫±ng", "l√†", "n√≥i", "nh·∫Øn", "g·ª≠i", "l√∫c", "v√†o", "nh√©", "nha", "·∫°", "nh√°", 
            "ngay", "b√¢y gi·ªù", "qua", "messenger", "zalo", "facebook", "telegram", 
            "instagram", "tiktok", "sms", "tin", "nh·∫Øn", "g·ª≠i", "cho", "t·ªõi", "ƒë·∫øn",
            "chi·ªÅu", "s√°ng", "tr∆∞a", "t·ªëi", "ƒë√™m", "nay", "mai", "h√¥m", "ng√†y", "tu·∫ßn", "th√°ng",
            "c·ªßa", "·ªü", "t·∫°i", "v·ªõi", "v√†", "ho·∫∑c", "hay", "n·∫øu", "khi", "sau", "tr∆∞·ªõc",
            "ƒëi·ªán", "kh·∫©n c·∫•p", "video", "con", "s·∫Ω", "ƒë√£", "c√≥", "v√¨", "b·ªã", "ƒëau", "b·ª•ng"
        ]
        
        words = receiver.split()
        cleaned_words = []
        
        for word in words:
            if word.lower() not in unwanted_words:
                cleaned_words.append(word)
        
        # Gi·ªõi h·∫°n 2-3 t·ª´ ƒë·ªÉ tr√°nh extract qu√° d√†i
        if len(cleaned_words) > 3:
            cleaned_words = cleaned_words[:3]
        
        return " ".join(cleaned_words).strip()
    
    def _clean_message(self, message: str) -> str:
        """L√†m s·∫°ch message entity"""
        unwanted_prefixes = ["r·∫±ng", "l√†", "n√≥i", "nh·∫Øn", "g·ª≠i"]
        
        for prefix in unwanted_prefixes:
            if message.lower().startswith(prefix + " "):
                message = message[len(prefix):].strip()
        
        return message.strip()
    
    def extract_all_entities(self, text: str) -> Dict[str, str]:
        """Extract t·∫•t c·∫£ entities cho h·ªá th·ªëng g·ªçi ƒëi·ªán/nh·∫Øn tin"""
        entities = {}
        
        receiver_result = self.extract_receiver(text)
        if receiver_result:
            entities.update(receiver_result)
        
        time_result = self.extract_time(text)
        if time_result:
            entities["TIME"] = time_result
        
        message_result = self.extract_message(text, entities.get("RECEIVER"))
        if message_result:
            entities["MESSAGE"] = message_result
        
        platform_result = self.extract_platform(text)
        if platform_result:
            entities["PLATFORM"] = platform_result
        
        return entities

# Test function
def test_entity_extraction():
    """Test c√°c tr∆∞·ªùng h·ª£p th·ª±c t·∫ø"""
    extractor = EntityExtractor()
    
    test_cases = [
        "g·ªçi cho b·ªë",
        "alo cho m·∫π",
        "nh·∫Øn tin cho b√† ngo·∫°i r·∫±ng t·ªëi con s·∫Ω v·ªÅ",
        "g·ª≠i tin nh·∫Øn qua Zalo cho ch·ªã H∆∞∆°ng",
        "g·ªçi video cho con g√°i",
        "nh·∫Øn tin qua Messenger t·ªõi B√† Sam r·∫±ng chi·ªÅu n√†y s·∫Ω qua nh√† b√† H√† ƒÉn r·∫±m l√∫c t√°m gi·ªù t·ªëi",
        "g·ªçi ngay cho b√°c sƒ©",
        "nh·∫Øn tin cho c·∫£ nh√† r·∫±ng t·ªëi nay ƒÉn c∆°m",
        "g·ªçi cho b√† ngo·∫°i c·ªßa con",
        "n·∫øu b·ªë g·ªçi th√¨ nh·∫Øn tin cho m·∫π",
    ]
    
    print("üß™ TESTING ENTITY EXTRACTION")
    print("=" * 60)
    
    for i, text in enumerate(test_cases, 1):
        print(f"\n{i}. Input: '{text}'")
        entities = extractor.extract_all_entities(text)
        
        if entities:
            for key, value in entities.items():
                print(f"   {key}: {value}")
        else:
            print("   ‚ùå Kh√¥ng extract ƒë∆∞·ª£c entities")

if __name__ == "__main__":
    test_entity_extraction()
