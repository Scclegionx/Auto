import os
from dataclasses import dataclass
from typing import List

class ModelConfig:
    """Cáº¥u hÃ¬nh Model - Thay Ä‘á»•i cÃ¡c tham sá»‘ dÆ°á»›i Ä‘Ã¢y Ä‘á»ƒ tá»‘i Æ°u"""
    
    def __init__(self):
        self.model_name = "vinai/phobert-large"
        self.model_size = "large"
        
        # Tham sá»‘ cÆ¡ báº£n
        self.max_length = 512  # 192 (tiáº¿t kiá»‡m) hoáº·c 512 (tá»‘i Æ°u)
        self.batch_size = 32     # 8 (tiáº¿t kiá»‡m) hoáº·c 32 (tá»‘i Æ°u)
        self.num_epochs = 20     # 5 (tiáº¿t kiá»‡m) hoáº·c 20 (tá»‘i Æ°u)
        self.learning_rate = 3e-5  # 1e-5 (tiáº¿t kiá»‡m) hoáº·c 3e-5 (tá»‘i Æ°u)
        self.freeze_layers = 4  # 8 (tiáº¿t kiá»‡m) hoáº·c 4 (tá»‘i Æ°u)
        
        import torch
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.use_fp16 = True  # False (tiáº¿t kiá»‡m) hoáº·c True (tá»‘i Æ°u)
        self.use_amp = True
        self.gradient_checkpointing = False  # True (tiáº¿t kiá»‡m) hoáº·c False (tá»‘i Æ°u)
        self.use_mixed_precision = True
        
        self.gradient_accumulation_steps = 1  # 4 (tiáº¿t kiá»‡m) hoáº·c 1 (tá»‘i Æ°u)
        self.weight_decay = 0.01
        self.adam_epsilon = 1e-8
        self.max_grad_norm = 1.0
        self.warmup_steps = 1000  # 300 (tiáº¿t kiá»‡m) hoáº·c 1000 (tá»‘i Æ°u)
        
        self.num_workers = 8  # 4 (tiáº¿t kiá»‡m) hoáº·c 8 (tá»‘i Æ°u)
        self.pin_memory = True
        self.dropout = 0.1  # 0.1 (tiáº¿t kiá»‡m) hoáº·c 0.1 (tá»‘i Æ°u)
        self.optimizer = "adamw"
    
    @property
    def hidden_size(self) -> int:
        """Láº¥y hidden size dá»±a trÃªn model size"""
        if self.model_size == "large":
            return 1024
        else:
            return 768
    
    @property
    def num_layers(self) -> int:
        """Láº¥y sá»‘ layers dá»±a trÃªn model size"""
        if self.model_size == "large":
            return 24
        else:
            return 12
    
    @property
    def num_attention_heads(self) -> int:
        """Láº¥y sá»‘ attention heads dá»±a trÃªn model size"""
        if self.model_size == "large":
            return 16
        else:
            return 12
    
    def __post_init__(self):
        """Validate model size vÃ  setup device"""
        if self.model_size not in ["base", "large"]:
            raise ValueError("model_size pháº£i lÃ  'base' hoáº·c 'large'")
        
        if self.device == "auto":
            import torch
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
            print(f"ðŸ–¥ï¸ Auto-detected device: {self.device}")
            
            if self.device == "cuda":
                print(f"ðŸŽ® GPU: {torch.cuda.get_device_name()}")
                print(f"ðŸ’¾ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")

@dataclass
class IntentConfig:
    """Cáº¥u hÃ¬nh cho Intent Recognition nÃ¢ng cao"""
    num_intents: int = 28  
    intent_labels: List[str] = None
    
    confidence_threshold: float = 0.7
    unknown_intent_label: str = "unknown"
    
    use_attention: bool = True
    num_attention_heads: int = 8
    attention_dropout: float = 0.1
    
    use_multi_layer: bool = True
    hidden_layer_sizes: List[int] = None  # Sáº½ Ä‘Æ°á»£c set Ä‘á»™ng dá»±a trÃªn model size
    
    use_crf: bool = False
    
    use_ensemble: bool = False
    ensemble_method: str = "weighted"  # "weighted", "voting", "stacking"
    
    use_confidence_scoring: bool = True
    use_batch_norm: bool = True
    use_residual_connections: bool = True
    
    def __post_init__(self):
        if self.intent_labels is None:
            self.intent_labels = [
                "adjust-settings", "app-tutorial", "browse-social-media", "call", 
                "check-device-status", "check-health-status", "check-messages", 
                "check-weather", "control-device", "general-conversation", 
                "make-call", "make-video-call", "navigation-help", "open-app", 
                "open-app-action", "play-audio", "play-content", "play-media", 
                "provide-instructions", "read-content", "read-news", "search-content", 
                "search-internet", "send-message", "send-mess", "set-alarm", 
                "set-reminder", "view-content"
            ]
        
        if self.hidden_layer_sizes is None:
            # Sá»­ dá»¥ng giÃ¡ trá»‹ máº·c Ä‘á»‹nh thay vÃ¬ relative import
            base_size = 768  # PhoBERT-base hidden size
            self.hidden_layer_sizes = [base_size, base_size // 2, base_size // 4]

@dataclass
class EntityConfig:
    """Cáº¥u hÃ¬nh cho Entity Extraction - Cáº­p nháº­t theo dataset má»›i"""
    entity_labels: List[str] = None
    
    def __post_init__(self):
        if self.entity_labels is None:
            self.entity_labels = [
                "O",  # Outside
                "FAMILY_RELATIONSHIP",  # Má»‘i quan há»‡ gia Ä‘Ã¬nh
                "DATE_EXPRESSION",      # Biá»ƒu thá»©c ngÃ y thÃ¡ng
                "CONTACT_PERSON",       # NgÆ°á»i liÃªn há»‡
                "LOCATION",             # Äá»‹a Ä‘iá»ƒm
                "TIME_EXPRESSION",      # Biá»ƒu thá»©c thá»i gian
                "ARTIST_NAME"           # TÃªn nghá»‡ sÄ©
            ]
    
    @property
    def num_entities(self) -> int:
        return len(self.entity_labels)

@dataclass
class ValueConfig:
    """Cáº¥u hÃ¬nh cho Value Extraction - Má»›i thÃªm"""
    value_labels: List[str] = None
    
    def __post_init__(self):
        if self.value_labels is None:
            self.value_labels = [
                "TIME_EXPRESSION",      # Biá»ƒu thá»©c thá»i gian
                "MESSAGE_CONTENT",      # Ná»™i dung tin nháº¯n
                "REMINDER_CONTENT",     # Ná»™i dung nháº¯c nhá»Ÿ
                "HEALTH_METRIC",        # Chá»‰ sá»‘ sá»©c khá»e
                "MEDIA_TYPE",           # Loáº¡i media
                "NEWS_CATEGORY",        # Danh má»¥c tin tá»©c
                "DATE_EXPRESSION",      # Biá»ƒu thá»©c ngÃ y thÃ¡ng
                "WEATHER_CONDITION",    # Äiá»u kiá»‡n thá»i tiáº¿t
                "MEDIA_CONTENT",        # Ná»™i dung media
                "CALL_TYPE",            # Loáº¡i cuá»™c gá»i
                "FREQUENCY",            # Táº§n suáº¥t
                "SYMPTOM",              # Triá»‡u chá»©ng
                "TOPIC_NEWS",           # Chá»§ Ä‘á» tin tá»©c
                "NEWS_SOURCE"           # Nguá»“n tin tá»©c
            ]
    
    @property
    def num_values(self) -> int:
        return len(self.value_labels)

@dataclass
class CommandConfig:
    """Cáº¥u hÃ¬nh cho Command Processing - Cáº­p nháº­t theo dataset thá»±c táº¿"""
    command_labels: List[str] = None
    
    def __post_init__(self):
        if self.command_labels is None:
            self.command_labels = [
                "adjust-settings", "app-tutorial", "browse-social-media", "call", 
                "check-device-status", "check-health-status", "check-messages", 
                "check-weather", "control-device", "general-conversation", 
                "make-call", "make-video-call", "navigation-help", "open-app", 
                "open-app-action", "play-audio", "play-content", "play-media", 
                "provide-instructions", "read-content", "read-news", "search-content", 
                "search-internet", "send-mess", "send-message", "set-alarm", 
                "set-reminder", "view-content", "unknown"
            ]
    
    @property
    def num_commands(self) -> int:
        return len(self.command_labels)

@dataclass
class TrainingConfig:
    """Cáº¥u hÃ¬nh cho training - Thay Ä‘á»•i cÃ¡c tham sá»‘ dÆ°á»›i Ä‘Ã¢y"""
    output_dir: str = "./models"
    data_dir: str = "./data"
    log_dir: str = "./logs"
    seed: int = 42
    device: str = "auto"
    
    # Tham sá»‘ training
    save_steps: int = 25      # 100 (tiáº¿t kiá»‡m) hoáº·c 25 (tá»‘i Æ°u)
    eval_steps: int = 25      # 100 (tiáº¿t kiá»‡m) hoáº·c 25 (tá»‘i Æ°u)
    logging_steps: int = 5    # 20 (tiáº¿t kiá»‡m) hoáº·c 5 (tá»‘i Æ°u)
    early_stopping_patience: int = 10  # 15 (tiáº¿t kiá»‡m) hoáº·c 10 (tá»‘i Æ°u)
    save_total_limit: int = 5  # 3 (tiáº¿t kiá»‡m) hoáº·c 5 (tá»‘i Æ°u)
    
    use_mixed_precision: bool = True
    max_grad_norm: float = 1.0
    save_best_only: bool = True  # False (tiáº¿t kiá»‡m) hoáº·c True (tá»‘i Æ°u)
    use_gradient_checkpointing: bool = False  # True (tiáº¿t kiá»‡m) hoáº·c False (tá»‘i Æ°u)
    use_fp16: bool = True
    use_amp: bool = True
    max_memory_usage: str = "auto"
    
    def __post_init__(self):
        os.makedirs(self.output_dir, exist_ok=True)
        os.makedirs(self.data_dir, exist_ok=True)
        os.makedirs(self.log_dir, exist_ok=True)

# Khá»Ÿi táº¡o cÃ¡c config
model_config = ModelConfig()
intent_config = IntentConfig()
entity_config = EntityConfig()
value_config = ValueConfig()
command_config = CommandConfig()
training_config = TrainingConfig()

print("ðŸ”§ Model Configuration:")
print(f"  Model: {model_config.model_name}")
print(f"  Size: {model_config.model_size}")
print(f"  Max Length: {model_config.max_length}")
print(f"  Batch Size: {model_config.batch_size}")
print(f"  Learning Rate: {model_config.learning_rate}")
print(f"  Epochs: {model_config.num_epochs}")
print(f"  Device: {model_config.device}")
print(f"  FP16: {model_config.use_fp16}")
print(f"  Gradient Checkpointing: {model_config.gradient_checkpointing}")
print(f"  Freeze Layers: {model_config.freeze_layers}")
print(f"  Optimizer: {model_config.optimizer}") 
