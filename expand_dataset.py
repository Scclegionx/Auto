import json
import random
import re
from typing import List, Dict
import numpy as np

class DatasetExpander:
    def __init__(self, original_file: str = "elderly_command_dataset_reduced.json"):
        self.original_file = original_file
        self.expanded_file = "elderly_command_dataset_expanded.json"
        
    def load_original_data(self) -> List[Dict]:
        with open(self.original_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        print(f"üìÇ Loaded {len(data)} samples from {self.original_file}")
        return data
    
    def expand_dataset(self, target_size: int = 1000) -> List[Dict]:
        original_data = self.load_original_data()
        current_size = len(original_data)
        
        if current_size >= target_size:
            print(f"‚úÖ Dataset already has {current_size} samples, no expansion needed")
            return original_data
        
        print(f"üöÄ Expanding dataset from {current_size} to {target_size} samples")

        command_counts = {}
        for item in original_data:
            command = item['command']
            command_counts[command] = command_counts.get(command, 0) + 1
        
        print(f"üìä Current command distribution:")
        for command, count in sorted(command_counts.items()):
            print(f"   {command}: {count} samples")

        total_needed = target_size - current_size
        expanded_data = original_data.copy()
        
        # Strategy 1: Augment existing samples
        print("üîÑ Strategy 1: Augmenting existing samples...")
        augmented_samples = self.augment_existing_samples(original_data, total_needed // 2)
        expanded_data.extend(augmented_samples)
        
        # Strategy 2: Generate new samples
        print("üîÑ Strategy 2: Generating new samples...")
        remaining_needed = target_size - len(expanded_data)
        if remaining_needed > 0:
            new_samples = self.generate_new_samples(original_data, remaining_needed)
            expanded_data.extend(new_samples)
        
        # Shuffle data
        random.shuffle(expanded_data)
        
        print(f"‚úÖ Expanded dataset to {len(expanded_data)} samples")
        return expanded_data
    
    def augment_existing_samples(self, data: List[Dict], num_samples: int) -> List[Dict]:
        """Augment existing samples b·∫±ng c√°ch thay ƒë·ªïi t·ª´ ng·ªØ"""
        augmented = []
        
        augmentation_templates = {
            'send-mess': [
                'Nh·∫Øn tin cho {person} r·∫±ng {message}',
                'G·ª≠i tin nh·∫Øn cho {person} n·ªôi dung {message}',
                'So·∫°n tin nh·∫Øn g·ª≠i {person} v·ªõi n·ªôi dung {message}',
                'Vi·∫øt tin nh·∫Øn cho {person} v·ªÅ {message}',
                'G·ª≠i cho {person} tin nh·∫Øn {message}'
            ],
            'make-call': [
                'G·ªçi ƒëi·ªán cho {person}',
                'Th·ª±c hi·ªán cu·ªôc g·ªçi ƒë·∫øn {person}',
                'Li√™n l·∫°c v·ªõi {person} qua ƒëi·ªán tho·∫°i',
                'G·ªçi {person} ngay b√¢y gi·ªù',
                'Th·ª±c hi·ªán cu·ªôc g·ªçi cho {person}'
            ],
            'search-content': [
                'T√¨m ki·∫øm {query}',
                'T√¨m th√¥ng tin v·ªÅ {query}',
                'Tra c·ª©u {query}',
                'T√¨m hi·ªÉu v·ªÅ {query}',
                'T√¨m ki·∫øm th√¥ng tin {query}'
            ],
            'play-content': [
                'Ph√°t {content}',
                'B·∫≠t {content}',
                'M·ªü {content}',
                'Ch·∫°y {content}',
                'Xem {content}'
            ],
            'set-reminder': [
                'ƒê·∫∑t nh·∫Øc nh·ªü {reminder}',
                'T·∫°o l·ªùi nh·∫Øc {reminder}',
                'ƒê·∫∑t l·ªãch nh·∫Øc {reminder}',
                'T·∫°o nh·∫Øc nh·ªü cho {reminder}',
                'ƒê·∫∑t b√°o th·ª©c cho {reminder}'
            ]
        }
        
        # Common entities
        persons = ['ch√°u V∆∞∆°ng', 'ch·ªã H∆∞∆°ng', 'anh Nam', 'b√† n·ªôi', '√¥ng n·ªôi', 'm·∫π', 'b·ªë', 'em g√°i', 'anh trai']
        messages = ['chi·ªÅu n√†y ƒë√≥n b√† t·∫°i c√¥ng vi√™n Th·ªëng nh·∫•t l√∫c 16h chi·ªÅu', 's√°ng mai c√≥ h·∫πn b√°c sƒ©', 't·ªëi nay v·ªÅ mu·ªôn', 'ƒë√£ nh·∫≠n ƒë∆∞·ª£c tin nh·∫Øn']
        queries = ['c√°ch n·∫•u ph·ªü', 'th·ªùi ti·∫øt h√¥m nay', 'tin t·ª©c m·ªõi nh·∫•t', 'c√¥ng th·ª©c l√†m b√°nh', 'ƒë·ªãa ch·ªâ b·ªánh vi·ªán']
        contents = ['nh·∫°c tr·ªØ t√¨nh', 'phim h√†i', 'video h∆∞·ªõng d·∫´n', 'b√†i h√°t m·ªõi', 'tin t·ª©c th·ªùi s·ª±']
        reminders = ['u·ªëng thu·ªëc l√∫c 8h s√°ng', 'h·ªçp gia ƒë√¨nh t·ªëi nay', 'ƒëi kh√°m b·ªánh ng√†y mai', 'g·ªçi ƒëi·ªán cho con']
        
        for _ in range(num_samples):
            # Ch·ªçn random sample
            sample = random.choice(data)
            command = sample['command']
            original_text = sample['input']
            
            # T·∫°o augmented version
            if command in augmentation_templates:
                template = random.choice(augmentation_templates[command])
                
                # Thay th·∫ø placeholders
                if '{person}' in template:
                    template = template.replace('{person}', random.choice(persons))
                if '{message}' in template:
                    template = template.replace('{message}', random.choice(messages))
                if '{query}' in template:
                    template = template.replace('{query}', random.choice(queries))
                if '{content}' in template:
                    template = template.replace('{content}', random.choice(contents))
                if '{reminder}' in template:
                    template = template.replace('{reminder}', random.choice(reminders))
                
                augmented_sample = {
                    'input': template,
                    'command': command
                }
                augmented.append(augmented_sample)
            else:
                # N·∫øu kh√¥ng c√≥ template, s·ª≠ d·ª•ng synonym replacement
                augmented_text = self.replace_synonyms(original_text)
                augmented_sample = {
                    'input': augmented_text,
                    'command': command
                }
                augmented.append(augmented_sample)
        
        return augmented
    
    def replace_synonyms(self, text: str) -> str:
        """Thay th·∫ø t·ª´ ƒë·ªìng nghƒ©a"""
        synonyms = {
            'nh·∫Øn tin': ['g·ª≠i tin nh·∫Øn', 'so·∫°n tin nh·∫Øn', 'vi·∫øt tin nh·∫Øn'],
            'g·ªçi ƒëi·ªán': ['g·ªçi', 'th·ª±c hi·ªán cu·ªôc g·ªçi', 'li√™n l·∫°c'],
            't√¨m ki·∫øm': ['t√¨m', 'tra c·ª©u', 't√¨m hi·ªÉu'],
            'ph√°t': ['b·∫≠t', 'm·ªü', 'ch·∫°y', 'xem'],
            'ƒë·∫∑t nh·∫Øc nh·ªü': ['t·∫°o l·ªùi nh·∫Øc', 'ƒë·∫∑t l·ªãch nh·∫Øc', 't·∫°o nh·∫Øc nh·ªü'],
            'ki·ªÉm tra': ['xem', 'ki·ªÉm tra', 'xem x√©t'],
            'm·ªü': ['b·∫≠t', 'kh·ªüi ƒë·ªông', 'ch·∫°y'],
            't·∫Øt': ['ƒë√≥ng', 'd·ª´ng', 'ng·∫Øt']
        }
        
        for word, syns in synonyms.items():
            if word in text:
                text = text.replace(word, random.choice(syns))
        
        return text
    
    def generate_new_samples(self, data: List[Dict], num_samples: int) -> List[Dict]:
        """T·∫°o samples m·ªõi d·ª±a tr√™n patterns"""
        new_samples = []
        
        # Patterns cho t·ª´ng command
        patterns = {
            'send-mess': [
                'Nh·∫Øn tin cho {person} r·∫±ng {message}',
                'G·ª≠i tin nh·∫Øn cho {person} n·ªôi dung {message}',
                'So·∫°n tin nh·∫Øn g·ª≠i {person} v·ªõi n·ªôi dung {message}'
            ],
            'make-call': [
                'G·ªçi ƒëi·ªán cho {person}',
                'Th·ª±c hi·ªán cu·ªôc g·ªçi ƒë·∫øn {person}',
                'Li√™n l·∫°c v·ªõi {person} qua ƒëi·ªán tho·∫°i'
            ],
            'search-content': [
                'T√¨m ki·∫øm {query}',
                'T√¨m th√¥ng tin v·ªÅ {query}',
                'Tra c·ª©u {query}',
                'T√¨m hi·ªÉu v·ªÅ {query}'
            ],
            'play-content': [
                'Ph√°t {content}',
                'B·∫≠t {content}',
                'M·ªü {content}',
                'Xem {content}'
            ],
            'set-reminder': [
                'ƒê·∫∑t nh·∫Øc nh·ªü {reminder}',
                'T·∫°o l·ªùi nh·∫Øc {reminder}',
                'ƒê·∫∑t l·ªãch nh·∫Øc {reminder}'
            ],
            'check-weather': [
                'Ki·ªÉm tra th·ªùi ti·∫øt h√¥m nay',
                'Xem d·ª± b√°o th·ªùi ti·∫øt',
                'Th·ªùi ti·∫øt nh∆∞ th·∫ø n√†o',
                'Nhi·ªát ƒë·ªô h√¥m nay bao nhi√™u'
            ],
            'check-messages': [
                'Ki·ªÉm tra tin nh·∫Øn t·ª´ {person}',
                'Xem tin nh·∫Øn m·ªõi',
                'ƒê·ªçc tin nh·∫Øn ch∆∞a ƒë·ªçc',
                'Ki·ªÉm tra h·ªôp th∆∞'
            ]
        }
        
        # Entities
        persons = ['ch√°u V∆∞∆°ng', 'ch·ªã H∆∞∆°ng', 'anh Nam', 'b√† n·ªôi', '√¥ng n·ªôi', 'm·∫π', 'b·ªë', 'em g√°i', 'anh trai', 'con trai', 'con g√°i']
        messages = [
            'chi·ªÅu n√†y ƒë√≥n b√† t·∫°i c√¥ng vi√™n Th·ªëng nh·∫•t l√∫c 16h chi·ªÅu',
            's√°ng mai c√≥ h·∫πn b√°c sƒ©',
            't·ªëi nay v·ªÅ mu·ªôn',
            'ƒë√£ nh·∫≠n ƒë∆∞·ª£c tin nh·∫Øn',
            'nh·ªõ u·ªëng thu·ªëc ƒë√∫ng gi·ªù',
            'c√≥ vi·ªác g·∫•p c·∫ßn li√™n l·∫°c'
        ]
        queries = [
            'c√°ch n·∫•u ph·ªü',
            'th·ªùi ti·∫øt h√¥m nay',
            'tin t·ª©c m·ªõi nh·∫•t',
            'c√¥ng th·ª©c l√†m b√°nh',
            'ƒë·ªãa ch·ªâ b·ªánh vi·ªán',
            'c√°ch s·ª≠ d·ª•ng ƒëi·ªán tho·∫°i',
            'th√¥ng tin v·ªÅ b·ªánh ti·ªÉu ƒë∆∞·ªùng',
            'ƒë·ªãa ƒëi·ªÉm du l·ªãch g·∫ßn ƒë√¢y'
        ]
        contents = [
            'nh·∫°c tr·ªØ t√¨nh',
            'phim h√†i',
            'video h∆∞·ªõng d·∫´n',
            'b√†i h√°t m·ªõi',
            'tin t·ª©c th·ªùi s·ª±',
            'nh·∫°c v√†ng',
            'phim h√†nh ƒë·ªông',
            'b√†i h√°t c≈©'
        ]
        reminders = [
            'u·ªëng thu·ªëc l√∫c 8h s√°ng',
            'h·ªçp gia ƒë√¨nh t·ªëi nay',
            'ƒëi kh√°m b·ªánh ng√†y mai',
            'g·ªçi ƒëi·ªán cho con',
            'ƒëi ch·ª£ s√°ng mai',
            'h·∫πn b√°c sƒ© tu·∫ßn sau'
        ]
        
        commands = list(patterns.keys())
        
        for _ in range(num_samples):
            command = random.choice(commands)
            if command in patterns:
                pattern = random.choice(patterns[command])
                
                # Thay th·∫ø placeholders
                if '{person}' in pattern:
                    pattern = pattern.replace('{person}', random.choice(persons))
                if '{message}' in pattern:
                    pattern = pattern.replace('{message}', random.choice(messages))
                if '{query}' in pattern:
                    pattern = pattern.replace('{query}', random.choice(queries))
                if '{content}' in pattern:
                    pattern = pattern.replace('{content}', random.choice(contents))
                if '{reminder}' in pattern:
                    pattern = pattern.replace('{reminder}', random.choice(reminders))
                
                new_sample = {
                    'input': pattern,
                    'command': command
                }
                new_samples.append(new_sample)
        
        return new_samples
    
    def save_expanded_data(self, data: List[Dict]):
        """L∆∞u dataset ƒë√£ m·ªü r·ªông"""
        with open(self.expanded_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"üíæ Saved expanded dataset to {self.expanded_file}")
        print(f"üìä File size: {len(json.dumps(data, ensure_ascii=False).encode()) / 1024:.2f} KB")
        
        # Ph√¢n t√≠ch distribution
        command_counts = {}
        for item in data:
            command = item['command']
            command_counts[command] = command_counts.get(command, 0) + 1
        
        print(f"üìà Final command distribution:")
        for command, count in sorted(command_counts.items()):
            percentage = (count / len(data)) * 100
            print(f"   {command}: {count} samples ({percentage:.1f}%)")

def main():
    """Main function"""
    print("üöÄ Dataset Expansion for PhoBERT-Large")
    print("=" * 50)
    
    # T·∫°o expander
    expander = DatasetExpander()
    
    # M·ªü r·ªông dataset ƒë·∫øn 1000 samples (khuy·∫øn ngh·ªã cho large model)
    expanded_data = expander.expand_dataset(target_size=1000)
    
    # L∆∞u dataset ƒë√£ m·ªü r·ªông
    expander.save_expanded_data(expanded_data)
    
    print("\nüéâ Dataset expansion completed!")
    print("üìã Next steps:")
    print("   1. Use the expanded dataset for training")
    print("   2. Run: python train_gpu.py")
    print("   3. The large model will have more data to learn from")

if __name__ == "__main__":
    main()
